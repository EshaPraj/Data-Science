{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b11f111f-67d3-4377-b66b-965b1aae5c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70403820-bf1e-48be-a92f-427abb412131",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"SAHeart.csv\", na_values = [\"NA\", '?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "479b54e9-4be4-4d1f-9931-e5155114a7ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row.names    0\n",
       "sbp          0\n",
       "tobacco      0\n",
       "ldl          0\n",
       "adiposity    0\n",
       "famhist      0\n",
       "typea        0\n",
       "obesity      0\n",
       "alcohol      0\n",
       "age          0\n",
       "chd          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c5663e1-e492-4126-8e44-e2106409ccf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sbp  tobacco   ldl  adiposity  typea  obesity  alcohol  age  chd\n",
      "0  160    12.00  5.73      23.11     49    25.30    97.20   52    1\n",
      "1  144     0.01  4.41      28.61     55    28.87     2.06   63    1\n",
      "2  118     0.08  3.48      32.28     52    29.14     3.81   46    0\n",
      "3  170     7.50  6.41      38.03     51    31.99    24.26   58    1\n",
      "4  134    13.60  3.50      27.78     60    25.99    57.34   49    1\n"
     ]
    }
   ],
   "source": [
    "# Drop 'row.names' and 'famhist' columns\n",
    "df = df.drop(columns=['row.names', 'famhist'])\n",
    "\n",
    "# Verify the columns are removed\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dcde9454-5e9c-4560-a7c3-6bd423af0ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input: x\n",
    "#output: y\n",
    "\n",
    "X = df.iloc[: , 1: 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ec34616a-e378-4d7a-8f29-13ef9eaa5210",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.iloc[:, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a28d7bd3-8d34-4442-a0f1-b0f687152bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features (X):\n",
      "   tobacco   ldl  adiposity  typea  obesity  alcohol  age  chd\n",
      "0    12.00  5.73      23.11     49    25.30    97.20   52    1\n",
      "1     0.01  4.41      28.61     55    28.87     2.06   63    1\n",
      "2     0.08  3.48      32.28     52    29.14     3.81   46    0\n",
      "3     7.50  6.41      38.03     51    31.99    24.26   58    1\n",
      "4    13.60  3.50      27.78     60    25.99    57.34   49    1\n",
      "\n",
      "Target (y):\n",
      "0    1\n",
      "1    1\n",
      "2    0\n",
      "3    1\n",
      "4    1\n",
      "Name: chd, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Features (X):\")\n",
    "print(X.head())\n",
    "print(\"\\nTarget (y):\")\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "68093267-23b6-46d7-b256-916ec12c8c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.25, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bfee2b00-b146-4ade-821d-82f8dabc4b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8d64d194-7e32-4ab3-84bd-dd7f57fa5fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7ff1ce5f-5166-4c27-bdad-1dda6f2cde42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(462, 8)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "90841a2d-6d0e-457d-8f88-9c6543105e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.3390 - loss: 3.5012 - val_accuracy: 0.4138 - val_loss: 2.9302\n",
      "Epoch 2/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4658 - loss: 2.1556 - val_accuracy: 0.4224 - val_loss: 1.9828\n",
      "Epoch 3/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4021 - loss: 1.5377 - val_accuracy: 0.5000 - val_loss: 1.2419\n",
      "Epoch 4/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5554 - loss: 0.9028 - val_accuracy: 0.5603 - val_loss: 0.8778\n",
      "Epoch 5/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6714 - loss: 0.6989 - val_accuracy: 0.5776 - val_loss: 0.8179\n",
      "Epoch 6/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6891 - loss: 0.6909 - val_accuracy: 0.6466 - val_loss: 0.7952\n",
      "Epoch 7/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6600 - loss: 0.6776 - val_accuracy: 0.5862 - val_loss: 0.7641\n",
      "Epoch 8/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7045 - loss: 0.5912 - val_accuracy: 0.6207 - val_loss: 0.7263\n",
      "Epoch 9/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6813 - loss: 0.6216 - val_accuracy: 0.5948 - val_loss: 0.7132\n",
      "Epoch 10/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7109 - loss: 0.5614 - val_accuracy: 0.6034 - val_loss: 0.6909\n",
      "Epoch 11/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6608 - loss: 0.6049 - val_accuracy: 0.6552 - val_loss: 0.6772\n",
      "Epoch 12/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7068 - loss: 0.5754 - val_accuracy: 0.6207 - val_loss: 0.6693\n",
      "Epoch 13/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6838 - loss: 0.5838 - val_accuracy: 0.6897 - val_loss: 0.6866\n",
      "Epoch 14/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7230 - loss: 0.5493 - val_accuracy: 0.5776 - val_loss: 0.7319\n",
      "Epoch 15/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5696 - loss: 0.6717 - val_accuracy: 0.6897 - val_loss: 0.6650\n",
      "Epoch 16/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6809 - loss: 0.5919 - val_accuracy: 0.6724 - val_loss: 0.6194\n",
      "Epoch 17/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7522 - loss: 0.5511 - val_accuracy: 0.6293 - val_loss: 0.6095\n",
      "Epoch 18/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7405 - loss: 0.5371 - val_accuracy: 0.6897 - val_loss: 0.5968\n",
      "Epoch 19/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7899 - loss: 0.5241 - val_accuracy: 0.6724 - val_loss: 0.5870\n",
      "Epoch 20/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7669 - loss: 0.5177 - val_accuracy: 0.7069 - val_loss: 0.5840\n",
      "Epoch 21/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7573 - loss: 0.5441 - val_accuracy: 0.7155 - val_loss: 0.5721\n",
      "Epoch 22/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7736 - loss: 0.4969 - val_accuracy: 0.7328 - val_loss: 0.5665\n",
      "Epoch 23/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7825 - loss: 0.5022 - val_accuracy: 0.7414 - val_loss: 0.5591\n",
      "Epoch 24/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7994 - loss: 0.4804 - val_accuracy: 0.7069 - val_loss: 0.5737\n",
      "Epoch 25/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7976 - loss: 0.4781 - val_accuracy: 0.7155 - val_loss: 0.5606\n",
      "Epoch 26/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7603 - loss: 0.5161 - val_accuracy: 0.7586 - val_loss: 0.5418\n",
      "Epoch 27/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7938 - loss: 0.4932 - val_accuracy: 0.7586 - val_loss: 0.5327\n",
      "Epoch 28/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8123 - loss: 0.4859 - val_accuracy: 0.7672 - val_loss: 0.5292\n",
      "Epoch 29/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8333 - loss: 0.4393 - val_accuracy: 0.7586 - val_loss: 0.5265\n",
      "Epoch 30/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8018 - loss: 0.4608 - val_accuracy: 0.7328 - val_loss: 0.5259\n",
      "Epoch 31/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8226 - loss: 0.4648 - val_accuracy: 0.7759 - val_loss: 0.5113\n",
      "Epoch 32/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8125 - loss: 0.4579 - val_accuracy: 0.7586 - val_loss: 0.5150\n",
      "Epoch 33/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7759 - loss: 0.4841 - val_accuracy: 0.7414 - val_loss: 0.5217\n",
      "Epoch 34/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8213 - loss: 0.4350 - val_accuracy: 0.8017 - val_loss: 0.4938\n",
      "Epoch 35/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8454 - loss: 0.4408 - val_accuracy: 0.7500 - val_loss: 0.4983\n",
      "Epoch 36/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8312 - loss: 0.4480 - val_accuracy: 0.8190 - val_loss: 0.4878\n",
      "Epoch 37/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8570 - loss: 0.4196 - val_accuracy: 0.8017 - val_loss: 0.4807\n",
      "Epoch 38/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8472 - loss: 0.4349 - val_accuracy: 0.7672 - val_loss: 0.4774\n",
      "Epoch 39/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8118 - loss: 0.4407 - val_accuracy: 0.7414 - val_loss: 0.4896\n",
      "Epoch 40/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7611 - loss: 0.4700 - val_accuracy: 0.8103 - val_loss: 0.4614\n",
      "Epoch 41/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8315 - loss: 0.4020 - val_accuracy: 0.7759 - val_loss: 0.4698\n",
      "Epoch 42/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8339 - loss: 0.4231 - val_accuracy: 0.8103 - val_loss: 0.4524\n",
      "Epoch 43/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8340 - loss: 0.4241 - val_accuracy: 0.8276 - val_loss: 0.4410\n",
      "Epoch 44/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8889 - loss: 0.3958 - val_accuracy: 0.8276 - val_loss: 0.4367\n",
      "Epoch 45/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8423 - loss: 0.4253 - val_accuracy: 0.7845 - val_loss: 0.4390\n",
      "Epoch 46/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8569 - loss: 0.3900 - val_accuracy: 0.8362 - val_loss: 0.4252\n",
      "Epoch 47/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9072 - loss: 0.3624 - val_accuracy: 0.8448 - val_loss: 0.4161\n",
      "Epoch 48/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8816 - loss: 0.3786 - val_accuracy: 0.8190 - val_loss: 0.4149\n",
      "Epoch 49/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8645 - loss: 0.3771 - val_accuracy: 0.8190 - val_loss: 0.4117\n",
      "Epoch 50/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8645 - loss: 0.4004 - val_accuracy: 0.7845 - val_loss: 0.4093\n",
      "Epoch 51/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8749 - loss: 0.3510 - val_accuracy: 0.8534 - val_loss: 0.4079\n",
      "Epoch 52/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9099 - loss: 0.3357 - val_accuracy: 0.8707 - val_loss: 0.3896\n",
      "Epoch 53/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8736 - loss: 0.3616 - val_accuracy: 0.8276 - val_loss: 0.3857\n",
      "Epoch 54/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8938 - loss: 0.3373 - val_accuracy: 0.8190 - val_loss: 0.3819\n",
      "Epoch 55/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8432 - loss: 0.3699 - val_accuracy: 0.8793 - val_loss: 0.3853\n",
      "Epoch 56/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8902 - loss: 0.3576 - val_accuracy: 0.8448 - val_loss: 0.3671\n",
      "Epoch 57/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9019 - loss: 0.3177 - val_accuracy: 0.8879 - val_loss: 0.3608\n",
      "Epoch 58/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9110 - loss: 0.3173 - val_accuracy: 0.8793 - val_loss: 0.3522\n",
      "Epoch 59/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9324 - loss: 0.3223 - val_accuracy: 0.8190 - val_loss: 0.3645\n",
      "Epoch 60/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8979 - loss: 0.3162 - val_accuracy: 0.8190 - val_loss: 0.3684\n",
      "Epoch 61/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8776 - loss: 0.3284 - val_accuracy: 0.8448 - val_loss: 0.3376\n",
      "Epoch 62/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8982 - loss: 0.3082 - val_accuracy: 0.9052 - val_loss: 0.3405\n",
      "Epoch 63/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9296 - loss: 0.3035 - val_accuracy: 0.8448 - val_loss: 0.3462\n",
      "Epoch 64/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9045 - loss: 0.2839 - val_accuracy: 0.9138 - val_loss: 0.3228\n",
      "Epoch 65/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9390 - loss: 0.2673 - val_accuracy: 0.9052 - val_loss: 0.3241\n",
      "Epoch 66/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8988 - loss: 0.2882 - val_accuracy: 0.9052 - val_loss: 0.3046\n",
      "Epoch 67/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9525 - loss: 0.2614 - val_accuracy: 0.9052 - val_loss: 0.3001\n",
      "Epoch 68/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9494 - loss: 0.2578 - val_accuracy: 0.9224 - val_loss: 0.3091\n",
      "Epoch 69/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9416 - loss: 0.2537 - val_accuracy: 0.9138 - val_loss: 0.2939\n",
      "Epoch 70/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9665 - loss: 0.2561 - val_accuracy: 0.9052 - val_loss: 0.2857\n",
      "Epoch 71/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9526 - loss: 0.2443 - val_accuracy: 0.9224 - val_loss: 0.2795\n",
      "Epoch 72/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9450 - loss: 0.2455 - val_accuracy: 0.9138 - val_loss: 0.2734\n",
      "Epoch 73/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9709 - loss: 0.2309 - val_accuracy: 0.9224 - val_loss: 0.2685\n",
      "Epoch 74/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9543 - loss: 0.2299 - val_accuracy: 0.8966 - val_loss: 0.2696\n",
      "Epoch 75/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9576 - loss: 0.2274 - val_accuracy: 0.8879 - val_loss: 0.2717\n",
      "Epoch 76/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9634 - loss: 0.2098 - val_accuracy: 0.9310 - val_loss: 0.2669\n",
      "Epoch 77/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9747 - loss: 0.2088 - val_accuracy: 0.9397 - val_loss: 0.2484\n",
      "Epoch 78/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9677 - loss: 0.2085 - val_accuracy: 0.9397 - val_loss: 0.2461\n",
      "Epoch 79/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9777 - loss: 0.2034 - val_accuracy: 0.9397 - val_loss: 0.2362\n",
      "Epoch 80/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9721 - loss: 0.1926 - val_accuracy: 0.9310 - val_loss: 0.2336\n",
      "Epoch 81/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9765 - loss: 0.1931 - val_accuracy: 0.9397 - val_loss: 0.2284\n",
      "Epoch 82/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9724 - loss: 0.1843 - val_accuracy: 0.9397 - val_loss: 0.2224\n",
      "Epoch 83/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9817 - loss: 0.1811 - val_accuracy: 0.9397 - val_loss: 0.2197\n",
      "Epoch 84/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9718 - loss: 0.1828 - val_accuracy: 0.9310 - val_loss: 0.2450\n",
      "Epoch 85/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9570 - loss: 0.2041 - val_accuracy: 0.9483 - val_loss: 0.2105\n",
      "Epoch 86/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9712 - loss: 0.1798 - val_accuracy: 0.9569 - val_loss: 0.2197\n",
      "Epoch 87/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9486 - loss: 0.1852 - val_accuracy: 0.9397 - val_loss: 0.2000\n",
      "Epoch 88/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9619 - loss: 0.1716 - val_accuracy: 0.9655 - val_loss: 0.1988\n",
      "Epoch 89/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9683 - loss: 0.1750 - val_accuracy: 0.9397 - val_loss: 0.2161\n",
      "Epoch 90/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9824 - loss: 0.1682 - val_accuracy: 0.9569 - val_loss: 0.1936\n",
      "Epoch 91/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9882 - loss: 0.1518 - val_accuracy: 0.9483 - val_loss: 0.1857\n",
      "Epoch 92/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9945 - loss: 0.1406 - val_accuracy: 0.9569 - val_loss: 0.1877\n",
      "Epoch 93/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9920 - loss: 0.1354 - val_accuracy: 0.9569 - val_loss: 0.1796\n",
      "Epoch 94/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9957 - loss: 0.1316 - val_accuracy: 0.9483 - val_loss: 0.1756\n",
      "Epoch 95/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9930 - loss: 0.1313 - val_accuracy: 0.9655 - val_loss: 0.1699\n",
      "Epoch 96/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9967 - loss: 0.1256 - val_accuracy: 0.9655 - val_loss: 0.1689\n",
      "Epoch 97/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9974 - loss: 0.1201 - val_accuracy: 0.9655 - val_loss: 0.1612\n",
      "Epoch 98/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9983 - loss: 0.1154 - val_accuracy: 0.9655 - val_loss: 0.1605\n",
      "Epoch 99/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9938 - loss: 0.1231 - val_accuracy: 0.9741 - val_loss: 0.1689\n",
      "Epoch 100/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9870 - loss: 0.1195 - val_accuracy: 0.9741 - val_loss: 0.1532\n",
      "Epoch 101/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9945 - loss: 0.1156 - val_accuracy: 0.9828 - val_loss: 0.1471\n",
      "Epoch 102/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9963 - loss: 0.1123 - val_accuracy: 0.9828 - val_loss: 0.1433\n",
      "Epoch 103/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9938 - loss: 0.1092 - val_accuracy: 0.9741 - val_loss: 0.1474\n",
      "Epoch 104/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9995 - loss: 0.1032 - val_accuracy: 0.9741 - val_loss: 0.1390\n",
      "Epoch 105/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9945 - loss: 0.1014 - val_accuracy: 0.9655 - val_loss: 0.1345\n",
      "Epoch 106/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0979 - val_accuracy: 0.9655 - val_loss: 0.1288\n",
      "Epoch 107/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0966 - val_accuracy: 0.9828 - val_loss: 0.1232\n",
      "Epoch 108/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0927 - val_accuracy: 0.9828 - val_loss: 0.1212\n",
      "Epoch 109/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0852 - val_accuracy: 0.9828 - val_loss: 0.1181\n",
      "Epoch 110/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9958 - loss: 0.0819 - val_accuracy: 0.9828 - val_loss: 0.1101\n",
      "Epoch 111/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0797 - val_accuracy: 0.9741 - val_loss: 0.1142\n",
      "Epoch 112/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0840 - val_accuracy: 0.9914 - val_loss: 0.1013\n",
      "Epoch 113/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0759 - val_accuracy: 0.9828 - val_loss: 0.0974\n",
      "Epoch 114/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0724 - val_accuracy: 0.9914 - val_loss: 0.0960\n",
      "Epoch 115/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0747 - val_accuracy: 0.9828 - val_loss: 0.0990\n",
      "Epoch 116/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0729 - val_accuracy: 0.9914 - val_loss: 0.0902\n",
      "Epoch 117/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0661 - val_accuracy: 0.9914 - val_loss: 0.0840\n",
      "Epoch 118/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0609 - val_accuracy: 1.0000 - val_loss: 0.0836\n",
      "Epoch 119/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0608 - val_accuracy: 0.9914 - val_loss: 0.0771\n",
      "Epoch 120/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0538 - val_accuracy: 0.9914 - val_loss: 0.0743\n",
      "Epoch 121/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0554 - val_accuracy: 1.0000 - val_loss: 0.0716\n",
      "Epoch 122/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0563 - val_accuracy: 1.0000 - val_loss: 0.0695\n",
      "Epoch 123/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0510 - val_accuracy: 1.0000 - val_loss: 0.0675\n",
      "Epoch 124/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0482 - val_accuracy: 0.9914 - val_loss: 0.0660\n",
      "Epoch 125/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0457 - val_accuracy: 0.9914 - val_loss: 0.0640\n",
      "Epoch 126/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0461 - val_accuracy: 1.0000 - val_loss: 0.0630\n",
      "Epoch 127/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0442 - val_accuracy: 1.0000 - val_loss: 0.0632\n",
      "Epoch 128/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0424 - val_accuracy: 1.0000 - val_loss: 0.0603\n",
      "Epoch 129/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0394 - val_accuracy: 1.0000 - val_loss: 0.0573\n",
      "Epoch 130/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0390 - val_accuracy: 1.0000 - val_loss: 0.0559\n",
      "Epoch 131/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0385 - val_accuracy: 1.0000 - val_loss: 0.0545\n",
      "Epoch 132/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0386 - val_accuracy: 0.9914 - val_loss: 0.0551\n",
      "Epoch 133/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0339 - val_accuracy: 1.0000 - val_loss: 0.0523\n",
      "Epoch 134/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0358 - val_accuracy: 0.9914 - val_loss: 0.0509\n",
      "Epoch 135/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0322 - val_accuracy: 0.9914 - val_loss: 0.0499\n",
      "Epoch 136/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0320 - val_accuracy: 1.0000 - val_loss: 0.0470\n",
      "Epoch 137/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0309 - val_accuracy: 0.9914 - val_loss: 0.0473\n",
      "Epoch 138/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0290 - val_accuracy: 1.0000 - val_loss: 0.0446\n",
      "Epoch 139/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0277 - val_accuracy: 1.0000 - val_loss: 0.0431\n",
      "Epoch 140/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0274 - val_accuracy: 1.0000 - val_loss: 0.0429\n",
      "Epoch 141/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0277 - val_accuracy: 1.0000 - val_loss: 0.0417\n",
      "Epoch 142/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0256 - val_accuracy: 1.0000 - val_loss: 0.0398\n",
      "Epoch 143/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0243 - val_accuracy: 1.0000 - val_loss: 0.0397\n",
      "Epoch 144/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0250 - val_accuracy: 1.0000 - val_loss: 0.0381\n",
      "Epoch 145/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0228 - val_accuracy: 0.9914 - val_loss: 0.0414\n",
      "Epoch 146/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0260 - val_accuracy: 1.0000 - val_loss: 0.0351\n",
      "Epoch 147/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0222 - val_accuracy: 1.0000 - val_loss: 0.0343\n",
      "Epoch 148/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0223 - val_accuracy: 1.0000 - val_loss: 0.0338\n",
      "Epoch 149/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0213 - val_accuracy: 1.0000 - val_loss: 0.0323\n",
      "Epoch 150/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0204 - val_accuracy: 1.0000 - val_loss: 0.0314\n",
      "Epoch 151/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0190 - val_accuracy: 1.0000 - val_loss: 0.0312\n",
      "Epoch 152/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0192 - val_accuracy: 1.0000 - val_loss: 0.0298\n",
      "Epoch 153/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0198 - val_accuracy: 1.0000 - val_loss: 0.0290\n",
      "Epoch 154/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0178 - val_accuracy: 1.0000 - val_loss: 0.0301\n",
      "Epoch 155/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0174 - val_accuracy: 1.0000 - val_loss: 0.0272\n",
      "Epoch 156/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0169 - val_accuracy: 1.0000 - val_loss: 0.0260\n",
      "Epoch 157/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0164 - val_accuracy: 1.0000 - val_loss: 0.0272\n",
      "Epoch 158/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0161 - val_accuracy: 1.0000 - val_loss: 0.0251\n",
      "Epoch 159/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0169 - val_accuracy: 1.0000 - val_loss: 0.0252\n",
      "Epoch 160/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0156 - val_accuracy: 1.0000 - val_loss: 0.0235\n",
      "Epoch 161/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0147 - val_accuracy: 1.0000 - val_loss: 0.0235\n",
      "Epoch 162/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0154 - val_accuracy: 1.0000 - val_loss: 0.0226\n",
      "Epoch 163/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0147 - val_accuracy: 1.0000 - val_loss: 0.0222\n",
      "Epoch 164/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0136 - val_accuracy: 1.0000 - val_loss: 0.0210\n",
      "Epoch 165/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0127 - val_accuracy: 1.0000 - val_loss: 0.0209\n",
      "Epoch 166/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0128 - val_accuracy: 1.0000 - val_loss: 0.0203\n",
      "Epoch 167/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0130 - val_accuracy: 1.0000 - val_loss: 0.0196\n",
      "Epoch 168/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0127 - val_accuracy: 1.0000 - val_loss: 0.0200\n",
      "Epoch 169/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0119 - val_accuracy: 1.0000 - val_loss: 0.0185\n",
      "Epoch 170/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0117 - val_accuracy: 1.0000 - val_loss: 0.0190\n",
      "Epoch 171/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0116 - val_accuracy: 1.0000 - val_loss: 0.0176\n",
      "Epoch 172/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0117 - val_accuracy: 1.0000 - val_loss: 0.0179\n",
      "Epoch 173/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0110 - val_accuracy: 1.0000 - val_loss: 0.0169\n",
      "Epoch 174/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0106 - val_accuracy: 1.0000 - val_loss: 0.0178\n",
      "Epoch 175/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0104 - val_accuracy: 1.0000 - val_loss: 0.0163\n",
      "Epoch 176/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0110 - val_accuracy: 1.0000 - val_loss: 0.0165\n",
      "Epoch 177/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0106 - val_accuracy: 1.0000 - val_loss: 0.0153\n",
      "Epoch 178/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0098 - val_accuracy: 1.0000 - val_loss: 0.0154\n",
      "Epoch 179/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0101 - val_accuracy: 1.0000 - val_loss: 0.0148\n",
      "Epoch 180/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0096 - val_accuracy: 1.0000 - val_loss: 0.0145\n",
      "Epoch 181/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0094 - val_accuracy: 1.0000 - val_loss: 0.0143\n",
      "Epoch 182/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0090 - val_accuracy: 1.0000 - val_loss: 0.0139\n",
      "Epoch 183/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0097 - val_accuracy: 1.0000 - val_loss: 0.0139\n",
      "Epoch 184/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0080 - val_accuracy: 1.0000 - val_loss: 0.0133\n",
      "Epoch 185/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0087 - val_accuracy: 1.0000 - val_loss: 0.0132\n",
      "Epoch 186/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0080 - val_accuracy: 1.0000 - val_loss: 0.0126\n",
      "Epoch 187/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0082 - val_accuracy: 1.0000 - val_loss: 0.0125\n",
      "Epoch 188/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0081 - val_accuracy: 1.0000 - val_loss: 0.0122\n",
      "Epoch 189/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0079 - val_accuracy: 1.0000 - val_loss: 0.0118\n",
      "Epoch 190/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0077 - val_accuracy: 1.0000 - val_loss: 0.0118\n",
      "Epoch 191/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0078 - val_accuracy: 1.0000 - val_loss: 0.0112\n",
      "Epoch 192/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 1.0000 - val_loss: 0.0114\n",
      "Epoch 193/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0075 - val_accuracy: 1.0000 - val_loss: 0.0111\n",
      "Epoch 194/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 1.0000 - val_loss: 0.0110\n",
      "Epoch 195/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 1.0000 - val_loss: 0.0107\n",
      "Epoch 196/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 1.0000 - val_loss: 0.0104\n",
      "Epoch 196: early stopping\n",
      "Restoring model weights from the end of the best epoch: 191.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x249e9c51040>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#defining a model\n",
    "model = Sequential(\n",
    "    [\n",
    "        Dense(25, input_dim = X.shape[1], activation = \"relu\" ), #hidden layer->7 wota neuron vayepani 25 wota input\n",
    "        Dense(10, activation = \"relu\"),\n",
    "        Dense(1, activation=\"sigmoid\") #output layer\n",
    "     ]\n",
    ")\n",
    "\n",
    "#compiling the model\n",
    "model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics=[\"accuracy\"]) #classificationvayera binary(0/1 ma output)\n",
    "\n",
    "#overfitting huna nadina lai early stopping\n",
    "monitor = EarlyStopping(\n",
    "    monitor = \"val_loss\", \n",
    "    min_delta = 1e-3, \n",
    "    patience = 5,\n",
    "    verbose = 1, \n",
    "    mode = \"auto\", \n",
    "    restore_best_weights = True )\n",
    "#restore_best_weights-> jun ma best accuracy/performance aako cha tyo lina lai\n",
    "#min_delta = 10^-3 minimum error eti samma matra\n",
    "\n",
    "#train our model \n",
    "\n",
    "#predict using this model\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          validation_data = (X_test, y_test), \n",
    "          callbacks = [monitor],\n",
    "          verbose = 1,\n",
    "          epochs = 1000\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ed47b420-66c7-47e3-9138-f8d33937b0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ae71d1e9-0404-4244-aa7c-ff0e7928b886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.0022997062)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b6c93a24-3e3f-46bb-b77b-a88cb82cf20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "#save garne model lai\n",
    "from tensorflow.keras.models import save_model\n",
    "save_model(model, \"assignmodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1cafd2be-a35a-4eaa-9803-08fbedbb9123",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model=load_model(\"assignmodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e1b58e62-f237-4419-ba2a-c416958a5b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [x for x in df.columns if x not in [\"chd\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "63c1b431-8da9-409d-a78b-390623d35455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sbp', 'tobacco', 'ldl', 'adiposity', 'typea', 'obesity', 'alcohol', 'age']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4efc3fe1-da04-40c0-bac6-fa7f11cb8f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sbp:{ min:101, max:218}\n",
      "tobacco:{ min:0.0, max:31.2}\n",
      "ldl:{ min:0.98, max:15.33}\n",
      "adiposity:{ min:6.74, max:42.49}\n",
      "typea:{ min:13, max:78}\n",
      "obesity:{ min:14.7, max:46.58}\n",
      "alcohol:{ min:0.0, max:147.19}\n",
      "age:{ min:15, max:64}\n"
     ]
    }
   ],
   "source": [
    "for i, name in enumerate(cols):\n",
    "    print(str(name) + \":\" + \"{ min:\" + str(df[name].min()) + \",\" + \" max:\" + str(df[name].max()) + \"}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4aa7de46-d75e-4a20-8686-43ac7bcecfa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sbp': {'min': 101, 'max': 218},\n",
       " 'tobacco': {'min': 0.0, 'max': 31.2},\n",
       " 'ldl': {'min': 0.98, 'max': 15.33},\n",
       " 'adiposity': {'min': 6.74, 'max': 42.49},\n",
       " 'typea': {'min': 13, 'max': 78},\n",
       " 'obesity': {'min': 14.7, 'max': 46.58},\n",
       " 'alcohol': {'min': 0.0, 'max': 147.19},\n",
       " 'age': {'min': 15, 'max': 64}}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "\"sbp\":{ \"min\":101, \"max\":218},\n",
    "\"tobacco\":{ \"min\":0.0, \"max\":31.2},\n",
    "\"ldl\":{ \"min\":0.98, \"max\":15.33},\n",
    "\"adiposity\":{ \"min\":6.74, \"max\":42.49},\n",
    "\"typea\":{ \"min\":13, \"max\":78},\n",
    "\"obesity\":{ \"min\":14.7, \"max\":46.58},\n",
    "\"alcohol\":{ \"min\":0.0, \"max\":147.19},\n",
    "\"age\":{ \"min\":15, \"max\":64}\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "832fd22e-700b-4623-8f7e-242e9fb79edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flask use garera web app ma testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f462a4be-287b-4355-b33a-c95b64647626",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
